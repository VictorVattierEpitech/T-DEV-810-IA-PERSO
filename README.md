# T-DEV-810

## Contexte et objectif
Ce projet vise Ã  construire un **classifieur multiâ€labels** pour dÃ©tecter plusieurs pathologies thoraciques Ã  partir de radiographies de thorax.

Voici les diffÃ©rentes pathologies Ã  identifier : 
- No Finding
- Enlarged Cardiomediastinum
- Cardiomegaly
- Lung Opacity
- Lung Lesion
- Edema
- Consolidation
- Pneumonia
- Atelectasis
- Pneumothorax
- Pleural Effusion
- Pleural Other
- Fracture
- Support Devices

## TÃ¢che de classification
- **Type** : classification **multiâ€labels** (une image peut appartenir Ã  plusieurs classes).  
- **EntrÃ©e** : image radiographique (224Ã—224 pixels, RGB)  
- **Sortie** : vecteur de 14 scores/logits, un par pathologie, convertis en probabilitÃ©s via une sigmoid.  
- **DÃ©cision** : on applique un seuil (par dÃ©faut 0.5 ou optimisÃ© par pathologie) pour chaque probabilitÃ© afin de produire un vecteur binaire de prÃ©Â­dicÂ­tions.

## Dataset : CheXpert
- **Source** : Stanford CheXpert (Irvin et al., 2019), grand jeu de donnÃ©es de radiographies thoraciques annotÃ©es de faÃ§on semiâ€automatique.  
- **Taille** :  
  - Environ **224 316** images dâ€™entraÃ®nement (version complÃ¨te),  
  - Ici downsampler pour limiter la taille du dataset (+ 400Go normalement)
  - Lien vers le dataset utilisÃ© : https://www.kaggle.com/datasets/ashery/chexpert
- **Ã‰tiquettes** : 14 catÃ©gories cliniques (ex. â€œNo Findingâ€, â€œPneumoniaâ€, â€œEdemaâ€â€¦).  
- **Valeurs des labels** :  
  - `1` = pathologie prÃ©sente  
  - `0` = pathologie absente  
  - `-1` = incertain (annotation douteuse)  
- **ParticularitÃ©s** :  
  - Jeu fortement dÃ©sÃ©quilibrÃ© (certaines pathologies trÃ¨s rares)  
  - Ã‰tiquettes produites par extraction automatique de rapports radiologiques, dâ€™oÃ¹ la prÃ©sence de cas â€œincertainsâ€ Ã  gÃ©rer par masquage ou mapping.

## Ã‰tude de nos donnÃ©es

RÃ©partition des labels : 

On remarque tout de suite un gros dÃ©sÃ©quilibre dans nos donnÃ©es, il faudra donc correctement gÃ©rÃ© ca au moment de l'entrainement.

![alt text](image.png)

## ModÃ¨le et architecture (model.py)


## Entrainement (train.py)

L'objectif est ici d'entrainer et de prendre en compte les diffÃ©rentes problÃ©matiques du dataset et des mÃ©canisme spÃ©cifique

* le **dÃ©sÃ©quilibre des classes** (ex : maladies rares),
* la **prÃ©sence de labels manquants** (non Ã©tiquetÃ©s),
* une **optimisation dynamique du learning rate**,

Chaque composant est choisi pour **maximiser la robustesse, la stabilitÃ© et la gÃ©nÃ©ralisation** du modÃ¨le.

### 1. ğŸ” Focal Loss MasquÃ©e

#### âœ… Pourquoi utiliser la **Focal Loss** ?

La **focal loss** a Ã©tÃ© introduite pour **gÃ©rer les classes dÃ©sÃ©quilibrÃ©es**

* Elle **rÃ©duit le poids des exemples bien classÃ©s**, pour que le modÃ¨le se concentre davantage sur ceux difficiles ou mal prÃ©dits.

#### Pourquoi **masquer** certaines donnÃ©es ?

Dans les datasets mÃ©dicaux (comme CheXpert), certains labels sont manquants (annotÃ©s -1). Ces cas ne doivent **pas contribuer Ã  la perte**.

Le masque binaire $\text{mask} \in \{0, 1\}$ permet d'**ignorer les labels inconnus** dans la backpropagation.


### 2. âš–ï¸ Oversampling ciblÃ© via `WeightedRandomSampler`

#### âš ï¸ ProblÃ¨me : classes trÃ¨s dÃ©sÃ©quilibrÃ©es

Certaines maladies sont **trÃ¨s rares** dans les donnÃ©es dâ€™entraÃ®nement.

#### ğŸ’¡ Solution : augmenter artificiellement la frÃ©quence des cas rares

On utilise un `WeightedRandomSampler` pour :

* donner **plus de chances dâ€™Ãªtre tirÃ©s** aux exemples **positifs valides** des classes rares,
* sans dupliquer rÃ©ellement les donnÃ©es.

On applique un **facteur multiplicatif** sur les poids des exemples positifs valides (selon la classe).

Cela permet de :

* **amÃ©liorer la couverture** des cas rares durant lâ€™entraÃ®nement,
* **rÃ©duire le biais** du modÃ¨le vers la prÃ©diction Â«â€¯tout est normalâ€¯Â».

### 3. Poids de classe dans la fonction de perte

#### ğŸ” Pourquoi pondÃ©rer les classes ?

MÃªme aprÃ¨s oversampling, certaines classes restent peu frÃ©quentes â†’ le modÃ¨le peut sous-optimiser ces sorties.

On calcule :

```python
pos_weight = neg / (pos + 1e-6)
```

* Chaque classe reÃ§oit un **poids proportionnel au ratio nÃ©gatifs/positifs**.
* Ces poids sont utilisÃ©s dans la `FocalLoss` (via `alpha`), pour **augmenter la pÃ©nalitÃ© dâ€™erreur sur les classes sous-reprÃ©sentÃ©es**.

### 4. OneCycle Learning Rate Scheduler

#### Pourquoi scheduler dynamiquement le learning rate ?

Le scheduler **OneCycleLR** est basÃ© sur les travaux de Leslie Smith. Il permet :

* dâ€™augmenter d'abord le learning rate (pour explorer largement),
* puis de le rÃ©duire progressivement (pour affiner la convergence).

Ce cycle :

* **accÃ©lÃ¨re la convergence**,
* **Ã©vite les minima locaux plats**,
* et **rÃ©duit le sur-apprentissage**.

### 5. EntraÃ®nement avec masquage et mÃ©triques robustes

#### EntraÃ®nement

* Les labels sont multi-labels binaires : chaque exemple peut avoir plusieurs classes positives.
* Le modÃ¨le sort des **logits bruts**, et la fonction de perte applique ensuite le **sigmoÃ¯de + BCE**.

#### Masquage dans la validation

On utilise un masque pour ignorer les labels invalides **aussi durant lâ€™Ã©valuation** :

```python
mask_flat = np.vstack(masks).flatten().astype(bool)
p_flat = preds_np.flatten()[mask_flat]
t_flat = trues_np.flatten()[mask_flat]
```

#### ğŸ“Š MÃ©triques multi-label :

* `accuracy` : exactitude globale.
* `precision`, `recall`, `f1_score` :

  * **macro-moyennÃ©s** (chaque classe compte autant),
  * **robustes aux classes dÃ©sÃ©quilibrÃ©es**,
  * utiles pour Ã©valuer la **qualitÃ© de la dÃ©tection des classes rares**.

### 7. ğŸ“ˆ Visualisation des courbes dâ€™entraÃ®nement

Ã€ la fin, on trace :

* la perte dâ€™entraÃ®nement et de validation,
* les mÃ©triques de performance.

Cela permet de :

* **visualiser la convergence**,
* **dÃ©tecter un overfitting**,
* **comparer diffÃ©rentes stratÃ©gies de sampling, loss ou architecture.**

## Evaluation

![alt text](./outputs_1/figures/confusion_per_class.png)

![alt text](./outputs_1/figures/ROC_AUC.png)

### RÃ©sultats et mÃ©triques

| Classe                         | PrÃ©cision | Rappel | F1-score | Support |
|-------------------------------|-----------|--------|----------|---------|
| No Finding                    | ğŸŸ¢ 0.99   | ğŸŸ¢ 1.00 | ğŸŸ¢ 1.00   | 3271    |
| Enlarged Cardiomediastinum    | ğŸŸ¢ 0.75   | ğŸŸ  0.56 | ğŸŸ  0.64   | 4740    |
| Cardiomegaly                  | ğŸŸ¢ 0.86   | ğŸŸ¢ 0.90 | ğŸŸ¢ 0.88   | 5692    |
| Lung Opacity                  | ğŸŸ¢ 0.94   | ğŸŸ¢ 1.00 | ğŸŸ¢ 0.97   | 17023   |
| Lung Lesion                   | ğŸŸ¢ 0.84   | ğŸŸ¢ 1.00 | ğŸŸ¢ 0.91   | 1593    |
| Edema                         | ğŸŸ¢ 0.91   | ğŸŸ¢ 1.00 | ğŸŸ¢ 0.95   | 33547   |
| Consolidation                 | ğŸŸ¢ 0.88   | ğŸŸ¢ 0.99 | ğŸŸ¢ 0.93   | 33547   |
| Pneumonia                     | ğŸŸ¢ 0.99   | ğŸŸ¢ 1.00 | ğŸŸ¢ 0.99   | 33547   |
| Atelectasis                   | ğŸ”´ 0.49   | ğŸ”´ 0.02 | ğŸ”´ 0.03   | 33547   |
| Pneumothorax                  | ğŸŸ  0.62   | ğŸŸ  0.40 | ğŸŸ  0.49   | 33547   |
| Pleural Effusion              | ğŸŸ¢ 0.87   | ğŸŸ¢ 0.97 | ğŸŸ¢ 0.92   | 33547   |
| Pleural Other                 | ğŸŸ¢ 0.86   | ğŸŸ¢ 1.00 | ğŸŸ¢ 0.93   | 629     |
| Fracture                      | ğŸŸ¢ 0.77   | ğŸŸ¢ 0.99 | ğŸŸ¢ 0.87   | 1665    |
| Support Devices               | ğŸŸ¢ 0.95   | ğŸŸ¢ 1.00 | ğŸŸ¢ 0.97   | 18340   |
| **Moyenne globale (macro)**   | ğŸŸ¢ **0.8370** | ğŸŸ¢ **0.8449** | ğŸŸ¢ **0.8199** | **-**   |

